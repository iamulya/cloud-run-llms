## LLM Playground

An example LLM Playground using LangChain, LangServe and Ollama. The repo uses Dockerfiles so the same code can be easily deployed on Compute / Serverless services like Cloud Run.

### Running Locally

You can either use the Dockerfile or directly use Ollama to start the backend.
